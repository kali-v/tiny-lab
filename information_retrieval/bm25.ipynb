{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BM25+\n",
    "\n",
    "BM25+ is an extension of the BM25 ranking function, which is a commonly used algorithm for information retrieval."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import numpy as np\n",
    "from typing import Dict\n",
    "\n",
    "\n",
    "class BM25Plus():\n",
    "    \"\"\"\n",
    "    Class for BM25+ ranking functionality.\n",
    "    Parameters\n",
    "    ----------\n",
    "    k1: float\n",
    "        BM25 k1 parameter. k1 is a variable which helps determine term frequency saturation characteristics.\n",
    "    b: float\n",
    "        BM25 b parameter. With bigger b, the effects of the length of the document compared to the average\n",
    "        length are more amplified.\n",
    "    d: float\n",
    "        BM25 d parameter. Delta parameter for BM25+.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, corpus: list, k1: float = 1.25, b: float = 0.75, d: float = 1):\n",
    "        \"\"\"\n",
    "        Parameters\n",
    "        ----------\n",
    "        corpus: list\n",
    "            list of documents\n",
    "        \"\"\"\n",
    "        self.k1 = k1\n",
    "        self.b = b\n",
    "        self.d = d\n",
    "\n",
    "        self.corpus = corpus\n",
    "        self.corpus_len = len(corpus)\n",
    "\n",
    "        self.doc_lens = [len(d) for d in corpus]\n",
    "        self.avgdl = sum(self.doc_lens) / len(self.doc_lens)\n",
    "        self.dfs = self.compute_dfs()\n",
    "\n",
    "    def compute_dfs(self) -> Dict[str, int]:\n",
    "        \"\"\"\n",
    "        Compute df for every word in corpus\n",
    "        Returns\n",
    "        -------\n",
    "            dictionary where each word has number of documents it occurs in.\n",
    "        \"\"\"\n",
    "        dfs: Dict[str, int] = {}\n",
    "\n",
    "        for doc in self.corpus:\n",
    "            doc_set = set(doc)  # remove duplicates in doc\n",
    "            for word in doc_set:\n",
    "                if word in dfs:\n",
    "                    dfs[word] += 1\n",
    "                else:\n",
    "                    dfs[word] = 1\n",
    "        return dfs\n",
    "\n",
    "    def get_idfs(self, doc: list) -> list:\n",
    "        \"\"\"\n",
    "        get idf for each word in doc\n",
    "        Parameters\n",
    "        ----------\n",
    "        doc: list\n",
    "            document as list of words\n",
    "        \"\"\"\n",
    "        idfs = []\n",
    "\n",
    "        for w in doc:\n",
    "            if w not in self.dfs:\n",
    "                idfs.append(0)\n",
    "                continue\n",
    "\n",
    "            df = self.dfs[w]\n",
    "            idfs.append(math.log((self.corpus_len - df + .5)/(df + .5) + self.d))\n",
    "        return idfs\n",
    "\n",
    "    def __call__(self, query: list) -> np.ndarray:\n",
    "        \"\"\"\n",
    "        Score documents in corpus for a query\n",
    "        Parameters\n",
    "        ----------\n",
    "        query: list\n",
    "            Preprocessed tokens\n",
    "        Returns\n",
    "        -------\n",
    "            Score for each document in corpus\n",
    "        \"\"\"\n",
    "        scores = np.zeros(self.corpus_len)\n",
    "        idfs = self.get_idfs(query)\n",
    "\n",
    "        for i, doc in enumerate(self.corpus):\n",
    "            L = self.doc_lens[i] / self.avgdl\n",
    "            # skip empty docs\n",
    "            if L == 0:\n",
    "                continue\n",
    "\n",
    "            # calculate scores\n",
    "            K = self.k1 * (1 - self.b + self.b * L)\n",
    "            for j, qword in enumerate(query):\n",
    "                tf = doc.count(qword)\n",
    "                # skip the word that not appear in the doc\n",
    "                if tf > 0:\n",
    "                    scores[i] += (tf / (tf + K)) * idfs[j]\n",
    "\n",
    "        return scores\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ! pip install git+https://github.com/MIR-MU/pv211-utils.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAP@10: 0.6966073959345643\n"
     ]
    }
   ],
   "source": [
    "from pv211_utils.irsystem import IRSystemBase\n",
    "from pv211_utils.datasets import CranfieldDataset\n",
    "from pv211_utils.evaluation_metrics import mean_average_precision\n",
    "from gensim.parsing.preprocessing import preprocess_string\n",
    "\n",
    "class BM25IRSystem(IRSystemBase):\n",
    "    def __init__(self):\n",
    "        docs_values = documents.values()\n",
    "        self.bm25 = BM25Plus([preprocess_string(doc.body) for doc in docs_values])\n",
    "        self.index = dict(enumerate(docs_values))\n",
    "\n",
    "    def search(self, query):\n",
    "        docs = self.bm25(preprocess_string(query.body)).argsort()[::-1]\n",
    "        for doc in docs:\n",
    "            yield self.index[doc]\n",
    "\n",
    "cranfield = CranfieldDataset(0.25)\n",
    "judgements = cranfield.load_test_judgements()\n",
    "queries = cranfield.load_test_queries()\n",
    "documents = cranfield.load_documents()\n",
    "\n",
    "bm25 = BM25IRSystem()\n",
    "\n",
    "result = mean_average_precision(system=bm25, queries=queries, judgements=judgements, k=10, num_processes=1)\n",
    "\n",
    "print(f\"MAP@10: {result}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "4525bb9afa5b11e91ff8883ff1427ebcb57df9afe31e89541862e2caa0e84c72"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
